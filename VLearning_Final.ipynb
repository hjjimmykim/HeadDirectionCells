{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProspectivePorpoise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjjimmykim/HeadDirectionCells/blob/master/VLearning_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yqVAD3zsUzb7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LOLA\n",
        "\n",
        "Ideas:\n",
        "1. RL vs. RL (multiagent)\n",
        "2. Communication channel (pre-set? deception?)\n",
        "3. LSTM stacked on FWN\n",
        "4. Induce RL to learn ZD-strategy (learn probabilities?)\n",
        "5. RL that adapts to opponent's non-stationary strategy"
      ]
    },
    {
      "metadata": {
        "id": "YjYwbRfHUrrr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ]
    },
    {
      "metadata": {
        "id": "N4ZntShaPaC7",
        "colab_type": "code",
        "outputId": "1f5ca73c-0a29-4adf-9272-b773fae4fb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Standard\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "import sympy as sp\n",
        "from scipy.optimize import fsolve"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kJYoceXaSPXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "iGsR8Ug0SAq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reward structure\n",
        "T = 5 # Temptation\n",
        "R = 3 # Reward\n",
        "P = 1 # Penalty\n",
        "S = 0 # Sucker\n",
        "\n",
        "#LOLA Reward structure\n",
        "#T = 0 # Temptation\n",
        "#R = -1 # Reward\n",
        "#P = -2 # Penalty\n",
        "#S = -3 # Sucker\n",
        "\n",
        "# Battle of the sexes\n",
        "T = 2\n",
        "R = 0\n",
        "P = 0\n",
        "S = 1\n",
        "\n",
        "# Two Nash Eq., one \n",
        "\n",
        "# Reward matrix (0 = cooperate, 1 = defect)\n",
        "RM = np.zeros([2,2])\n",
        "RM[0][0] = R\n",
        "RM[0][1] = S\n",
        "RM[1][0] = T\n",
        "RM[1][1] = P\n",
        "\n",
        "# RL\n",
        "gamma1 = 0.6 # Decay rate\n",
        "alpha1 = 0.005 # Learning rate\n",
        "gamma2 = 0.9 # Decay rate\n",
        "alpha2 = 0.005 # Learning rate\n",
        "\n",
        "# Simulation\n",
        "n_eps = 3       # Training episodes\n",
        "n_steps = 300      # Training steps\n",
        "n_turns = 10000       # Turns in the test game\n",
        "n_rec = 50        # For printing purposes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eX1tZFMXYgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "qTQSw7yQgSpw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converts action-pair [a1,a2] into a scalar state (0,1,2,3,4)\n",
        "def action_to_state(a1,a2):\n",
        "  \n",
        "  if a1 == -1 and a2 == -1: # Initial\n",
        "    s = 0\n",
        "  elif a1 == 0 and a2 == 0: # CC\n",
        "    s = 1\n",
        "  elif a1 == 0 and a2 == 1: # CD\n",
        "    s = 2\n",
        "  elif a1 == 1 and a2 == 0: # DC\n",
        "    s = 3\n",
        "  elif a1 == 1 and a2 == 1: # DD\n",
        "    s = 4\n",
        "    \n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDCUTuUnk6uh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mathematica2py(input = 'V.txt', ID_me=1, ID_otherguy=2):\n",
        "    f = open(input)\n",
        "\n",
        "    text = f.read()\n",
        "\n",
        "    text = ''.join(text.split()) # Remove whitespace\n",
        "    text = text.replace('^','**') # Replace ^ with **\n",
        "\n",
        "    num_terms = text.count('{')\n",
        "    \n",
        "    # Extract terms and get rid of curly braces\n",
        "    terms = []\n",
        "    \n",
        "    # Scalar-valued\n",
        "    if text.find(',') == -1:\n",
        "      return text\n",
        "    \n",
        "    # Vector-valued\n",
        "    while text.find(',') > -1:\n",
        "      return([x.strip('{').strip('}') for x in text.split(',')])\n",
        "      cut_point = text.find(',')\n",
        "      terms.append(text[:cut_point].strip('{').strip('}'))\n",
        "      text = text[cut_point+1:]\n",
        "        \n",
        "    return terms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SO2KyLlmpnAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_gradient(dV, a, b, gamma_, gamma2_ = '0'):\n",
        "  # dV = output of mathematica2py\n",
        "  # a = my policy\n",
        "  # b = other guy's policy\n",
        "  \n",
        "  a0 = a[0]\n",
        "  a1 = a[1]\n",
        "  a2 = a[2]\n",
        "  a3 = a[3]\n",
        "  a4 = a[4]\n",
        "  \n",
        "  b0 = b[0]\n",
        "  b1 = b[1]\n",
        "  b2 = b[2]\n",
        "  b3 = b[3]\n",
        "  b4 = b[4]\n",
        "  \n",
        "  gamma = gamma_\n",
        "  gamma2 = gamma2_\n",
        "  \n",
        "  return eval(dV)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwlRq6XoB0cS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_gamma(dV, a, b):\n",
        "\n",
        "  gamma = sp.Symbol('gamma',positive=True)\n",
        "\n",
        "  small = 1e-8\n",
        "  \n",
        "  #return sp.nsolve(eval(dV),gamma,(0.9))\n",
        "\n",
        "  def f1(gamma):\n",
        "    a0 = a[0]\n",
        "    a1 = a[1]\n",
        "    a2 = a[2]\n",
        "    a3 = a[3]\n",
        "    a4 = a[4]\n",
        "\n",
        "    b0 = b[0]\n",
        "    b1 = b[1]\n",
        "    b2 = b[2]\n",
        "    b3 = b[3]\n",
        "    b4 = b[4]\n",
        "    \n",
        "    return eval(dV)\n",
        "  \n",
        "  #f1 = lambda gamma: eval(dV)\n",
        "  \n",
        "  return fsolve(f1,0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4Sie6LRi6j4",
        "colab_type": "code",
        "outputId": "95b733ea-4eed-4cea-9a0f-761b3f22f952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "V = mathematica2py('V.txt') # Value function (5 elements for each state)\n",
        "\n",
        "# Gradients\n",
        "DVme = [] # w.r.t. my parameters (ai's)\n",
        "for i in range(5):\n",
        "  DVme.append(mathematica2py('DVa' + str(i) + '_total.txt'))\n",
        "LOLA_total = mathematica2py('LOLA_total.txt')\n",
        "  \n",
        "'''\n",
        "DVotherguy = [] # w.r.t. other guy's parameters (bi's)\n",
        "for i in range(5):\n",
        "  DVotherguy.append(mathematica2py('DVb' + str(i) + '.txt'))\n",
        "'''\n",
        "\n",
        "# Note: state = (player a, player b)\n",
        "\n",
        "p1 = []\n",
        "for i in range(5):\n",
        "  p1.append(np.random.random())\n",
        "# All-coop\n",
        "p1 = [1,1,1,1,1]\n",
        "# All-defect\n",
        "#p1 = [0,0,0,0,0]\n",
        "p1=[0.5,0.5,0.5,0.5,0.5]\n",
        "\n",
        "p2 = []\n",
        "for i in range(5):\n",
        "  p2.append(np.random.random())\n",
        "p2=[1,1,1,1,1]\n",
        "p2=[0.5,0.5,0.5,0.5,0.5]\n",
        "# Win-stay-lose-shift\n",
        "#p2 = [1,1,0,0,1]\n",
        "# Tit-for-tat\n",
        "p2 = [1,1,1,0,0]\n",
        "# ZD-strategy with extortion factor 3\n",
        "#p2 = [0,11/13,7/26,1/2,0]\n",
        "#p2 = [0,9/13,7/13,0,0]\n",
        "#p2 = [0,12/13,7/52,3/4,0]\n",
        "\n",
        "# DVme[i][j] = Gradient of state j value function with respect to a_i\n",
        "# DVotherguy[i][j] = Gradient of state j value function with respect to b_i\n",
        "# second index j does not exist if using total value function (sum over j's)\n",
        "\n",
        "#print(evaluate_gradient(DVme[0][0], p1, p2))\n",
        "\n",
        "# p2 stable for high gamma\n",
        "#p1=[0.26359499,0,0.13090269,0.2684707,0]\n",
        "#p2=[0,1,0,0,1]\n",
        "\n",
        "# Stable coop?\n",
        "p1 = [1,1,0.2,1,0.5]\n",
        "p2 = [1,1,1,0,0.5]\n",
        "\n",
        "p1 = [0,0,0,0,0]\n",
        "p1 = []\n",
        "for i in range(5):\n",
        "  p1.append(np.random.random())\n",
        "p1 = [0.32890504, 0.72718054, 0.29262048, 0.60808543999, 0.120000974]\n",
        "\n",
        "p1 = [0.5,0.5,0.5,0.5,0.5]\n",
        "p2 = [0.5,0.5,0.5,0.5,0.5]\n",
        "print(p1)\n",
        "print(p2)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5, 0.5, 0.5, 0.5, 0.5]\n",
            "[0.5, 0.5, 0.5, 0.5, 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pUxFvSmTUOfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Game"
      ]
    },
    {
      "metadata": {
        "id": "K3POCMTwgz6T",
        "colab_type": "code",
        "outputId": "7a2a3b10-68fb-4198-df8f-b6d33ca12f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "cell_type": "code",
      "source": [
        "t_start = time.time()\n",
        "t1 = time.time()\n",
        "\n",
        "max_crit_gamma_list1 = []\n",
        "max_crit_gamma_list2 = []\n",
        "\n",
        "\n",
        "# Gradient ascent\n",
        "for i_ep in range(n_steps): \n",
        "\n",
        "    # To make updates simultaneous\n",
        "    p1_old = copy.deepcopy(p1)\n",
        "    p2_old = copy.deepcopy(p2) \n",
        "    \n",
        "    for i_pol in range(5):\n",
        "            \n",
        "      # Naive step for agent 1\n",
        "      p1[i_pol] = p1[i_pol] + alpha1*evaluate_gradient(DVme[i_pol],p1_old,p2_old,gamma1)      \n",
        "      \n",
        "      # LOLA step for agent 1\n",
        "      #p1[i_pol] = p1[i_pol] + evaluate_gradient(LOLA_total[i_pol],p1_old,p2_old,gamma1,gamma2) * alpha1 * alpha2\n",
        "\n",
        "      # Naive step for agent 2\n",
        "      p2_old[2],p2_old[3] = p2_old[3],p2_old[2] # Switch CD & DC\n",
        "      p1_old[2],p1_old[3] = p1_old[3],p1_old[2]\n",
        "      p2[i_pol] = p2[i_pol] + alpha2*evaluate_gradient(DVme[i_pol],p2_old,p1_old,gamma2)\n",
        "      p1_old[2],p1_old[3] = p1_old[3],p1_old[2]\n",
        "      p2_old[2],p2_old[3] = p2_old[3],p2_old[2]\n",
        "      \n",
        "      # Probability constraints\n",
        "      p1[i_pol] = min(max(0,p1[i_pol]),1)\n",
        "      p2[i_pol] = min(max(0,p2[i_pol]),1)\n",
        "\n",
        "    if i_ep % n_rec == 0 and i_ep != 0: \n",
        "      t2 = time.time()\n",
        "      print('-----------------------------')\n",
        "      print('Episode ' + str(i_ep))\n",
        "      print(p1)\n",
        "      print(p2)\n",
        "      print('Runtime for episodes ' + str(i_ep - n_rec) + '-' + str(i_ep) + ': ' + str(t2-t1) + ' s')\n",
        "      \n",
        "      t1 = t2\n",
        "      \n",
        "      print('Critical gammas:')\n",
        "      \n",
        "      #Find critical gammas\n",
        "      fg1_list = []\n",
        "      fg2_list = []\n",
        "      for i_pol in range(5):\n",
        "        \n",
        "        fg1 = find_gamma(DVme[i_pol],p1,p2)\n",
        "        \n",
        "        # For nsolve\n",
        "        if fg1 > 0:\n",
        "          fg1_list.append(fg1[0])\n",
        "        else:\n",
        "          fg1_list.append(np.Inf)\n",
        "        \n",
        "        # For solve\n",
        "        #if len(fg1) > 0:\n",
        "        #fg1_list.append(fg1)[0])\n",
        "        #else:\n",
        "        #  fg1_list.append(np.Inf)\n",
        "        \n",
        "\n",
        "        p2[2],p2[3] = p2[3],p2[2] # Switch CD & DC\n",
        "        p1[2],p1[3] = p1[3],p1[2]\n",
        "        \n",
        "        fg2 = find_gamma(DVme[i_pol],p2,p1)\n",
        "        \n",
        "        if fg2 > 0:\n",
        "          fg2_list.append(fg2[0])\n",
        "        else:\n",
        "          fg2_list.append(np.Inf)\n",
        "          \n",
        "        #if len(fg2) > 0:\n",
        "        #fg2_list.append(fg2)[0])\n",
        "        #else:\n",
        "        #  fg2_list.append(np.Inf)\n",
        "\n",
        "        p1[2],p1[3] = p1[3],p1[2]\n",
        "        p2[2],p2[3] = p2[3],p2[2]\n",
        "\n",
        "        \n",
        "      print(fg1_list)\n",
        "      print(fg2_list)\n",
        "      print('Max. crit. gamma for player 1:',max(fg1_list))\n",
        "      print('Max. crit. gamma for player 2:',max(fg2_list))\n",
        "      \n",
        "      max_crit_gamma_list1.append(max(fg1_list))\n",
        "      max_crit_gamma_list2.append(max(fg2_list))\n",
        "\n",
        "      print('-----------------------------')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "Episode 50\n",
            "[0.449944290162481, 0.5824460223545668, 0.9628584060618461, 0.6442887017831588, 0.8944623393428434]\n",
            "[0.36445439440037053, 0, 0, 0, 0]\n",
            "Runtime for episodes 0-50: 17.122862100601196 s\n",
            "Critical gammas:\n",
            "[inf, inf, inf, inf, inf]\n",
            "[inf, inf, inf, inf, inf]\n",
            "Max. crit. gamma for player 1: inf\n",
            "Max. crit. gamma for player 2: inf\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "Episode 100\n",
            "[0.4819921528851481, 0.7452074651252341, 1, 0.8091442476925869, 1]\n",
            "[0.16004639481024674, 0, 0, 0, 0]\n",
            "Runtime for episodes 50-100: 24.787660121917725 s\n",
            "Critical gammas:\n",
            "[inf, inf, inf, inf, inf]\n",
            "[inf, inf, inf, inf, inf]\n",
            "Max. crit. gamma for player 1: inf\n",
            "Max. crit. gamma for player 2: inf\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "Episode 150\n",
            "[0.6006817712490349, 0.8983459989818003, 1, 0.9621886960271776, 1]\n",
            "[0, 0, 0, 0, 0]\n",
            "Runtime for episodes 100-150: 24.145750522613525 s\n",
            "Critical gammas:\n",
            "[inf, inf, inf, inf, inf]\n",
            "[inf, inf, inf, inf, inf]\n",
            "Max. crit. gamma for player 1: inf\n",
            "Max. crit. gamma for player 2: inf\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "Episode 200\n",
            "[0.750681771249035, 1, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0]\n",
            "Runtime for episodes 150-200: 23.585957288742065 s\n",
            "Critical gammas:\n",
            "[inf, inf, inf, inf, inf]\n",
            "[inf, inf, inf, inf, inf]\n",
            "Max. crit. gamma for player 1: inf\n",
            "Max. crit. gamma for player 2: inf\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "Episode 250\n",
            "[0.9006817712490351, 1, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0]\n",
            "Runtime for episodes 200-250: 23.106477975845337 s\n",
            "Critical gammas:\n",
            "[inf, inf, inf, inf, inf]\n",
            "[inf, inf, inf, inf, inf]\n",
            "Max. crit. gamma for player 1: inf\n",
            "Max. crit. gamma for player 2: inf\n",
            "-----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Va0YJ3VLritj",
        "colab_type": "code",
        "outputId": "0998f735-09e9-4e1f-eb6a-537092300cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# Test game\n",
        "p1 = [1,0,0,0,1]\n",
        "\n",
        "# Keep track of rewards\n",
        "rewards1 = np.zeros([n_turns,1])\n",
        "rewards2 = np.zeros([n_turns,1])\n",
        "\n",
        "# Keep track of actions\n",
        "actions1 = np.zeros([n_turns,1])\n",
        "actions2 = np.zeros([n_turns,1])\n",
        "\n",
        "# Initial state\n",
        "s = 0\n",
        "\n",
        "for i_turn in range(n_turns):\n",
        "\n",
        "  # Choose action\n",
        "  # 0 = cooperate, 1 = defect\n",
        "  a1 = int(np.random.rand(1) > p1[s])\n",
        "  a2 = int(np.random.rand(1) > p2[s])\n",
        "  \n",
        "  actions1[i_turn] = a1\n",
        "  actions2[i_turn] = a2\n",
        "\n",
        "  # Get rewards\n",
        "  r1 = RM[a1][a2]\n",
        "  r2 = RM[a2][a1]\n",
        "\n",
        "  rewards1[i_turn] = r1\n",
        "  rewards2[i_turn] = r2\n",
        "\n",
        "  # Update the state\n",
        "  s = action_to_state(a1,a2)\n",
        "\n",
        "#print(actions1)\n",
        "#print(actions2)\n",
        "print(np.sum(rewards1)/n_turns)\n",
        "print(np.sum(rewards2)/n_turns)\n",
        "  \n",
        "print('Total runtime: ' + str(time.time() - t_start) + ' s')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "1.0\n",
            "Total runtime: 301.60312485694885 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hoP2eQdkJCCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "2.3592/3.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQqoMYirqL7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dVme"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoEHaXpMvBiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if 1 in b:\n",
        "  b.remove(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhRdSHOtzWaD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzoi_0BbaZ6W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Abstract\n",
        "\n",
        "Dynamical Implications of Hyperparameters in Reinforcement Learning\n",
        "\n",
        "Reinforcement learning has been gaining popularity within the physics research community over past several years. Many of the algorithms require selection of hyperparameters, and it is unclear how these choices affect the learned policy. Often in practice, researchers choose hyperparameters for their simulations using brute force methods such as exhaustive grid search or heuristics without fully understanding how they may alter the effective reward structure and the corresponding value function landscape. Here, we investigate the possibility of using nonlinear dynamics approach to more rigorously guide our selection and adaptive optimization of appropriate parameters that are better aligned to achieve particular aims of the agent. We then extend our investigation to the setting of multiagent reinforcement learning and game theory to see how the choice of agent hyperparameters interplay with each other in competitive, cooperative, and mixed settings."
      ]
    },
    {
      "metadata": {
        "id": "X-awRckKBNxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1) Find toy problem for analytics and motivation\n",
        "\n",
        "1a) Can use perturbation theory for small gamma?\n",
        "\n",
        "2) Numerical simulations for gamma trajectories => explanation for why naive learners fail to cooperate?\n",
        "\n",
        "3) Optimal gamma as a function of turns?\n",
        "\n",
        "4) Tournament gammas (evolutionary algorithm?)\n",
        "\n",
        "5) RL controller to adjust gamma in real time? Meta RL controlling naive learner."
      ]
    },
    {
      "metadata": {
        "id": "wVqj37eV7b10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}